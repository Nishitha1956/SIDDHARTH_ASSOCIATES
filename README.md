ğŸ“¦ International Trade Data Analysis & End-to-End Data Pipeline
(Siddharth Associates â€“ 2017 to 2025 Import Data)

This project builds a complete data engineering and analytics pipeline for processing international import trade data (2017â€“2025).
The organization currently receives raw data from trade data providers (Seair/Eximpedia), and the goal is to automate the entire workflowâ€”from raw Excel files to dashboards and insights.

The final pipeline cleans, transforms, loads, and visualizes trade data, enabling the company to make better business decisions.

ğŸš€ Project Objectives

Convert raw, messy Excel data into a clean, structured dataset.

Parse unstructured fields like Goods Description to extract useful attributes (model, material, capacity, etc.).

Standardize all units, compute financial metrics, and generate additional derived fields.

Load processed data into a SQL database.

Build analytical reports and dashboards using Power BI.

Automate the pipeline to ensure repeatable, reliable analysis.

ğŸ› ï¸ Tech Stack

Python â€“ Data cleaning, transformations, parsing

Pandas / NumPy â€“ Data preprocessing

Regex â€“ Goods description parsing

MySQL â€“ Data warehouse & analytical storage

Power BI â€“ Interactive dashboards

Excel/CSV â€“ Input and intermediate files

GitHub â€“ Version control & documentation

ğŸ“‚ Pipeline Stages
1. Data Ingestion

Import raw Excel files (2017â€“Aug 2025).

Standardize column names.

Remove duplicates & blank rows.

Save intermediate output as cleaned CSV.

2. Data Cleaning & Transformation (Python)

Remove noise characters and unnecessary spacing.

Extract structured fields from â€œGoods Descriptionâ€, such as:

Model / Model No

Material

Capacity

Wattage

Size

Brand

Convert units (KG/MT/Units).

Convert all currency values to INR if applicable.

Compute new metrics:

Grand Total (Value + Duty)

Landed Cost Per Unit

Per-Unit Price

Total Duty %

Save processed dataset.

3. Loading into SQL Database

Create database: trade_analysis

Create table: shipments

Load processed CSV into SQL using a Python script.

Verify row count, data integrity, and indexing.

Enable analytics queries.

4. Power BI Dashboard Development

Four dashboards created:

a) Macro Trends Dashboard

Yearly import value

Monthly trend

Duty impact

YoY comparison

b) Category / Subcategory Analysis

Product category contribution

Subcategory drilldown

Model-level performance

c) Supplier Analytics

Top suppliers

Supplier share

Active vs inactive suppliers

d) Unit Economics Dashboard

Landed cost per model

Capacity vs cost scatter

Quantity vs cost distribution

Includes slicers for:

Year, category, supplier, country, HSN code, etc.

ğŸ“Š Key Insights Enabled

Track import trends from 2017â€“2025.

Identify high-performing categories and models.

Understand cost structures and margin drivers.

Monitor supplier contribution and dependency.

Support strategic sourcing & procurement decisions.

ğŸ“ Repository Structure
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw Excel files (2017â€“2025)
â”‚   â”œâ”€â”€ processed/          # Cleaned & transformed files
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_cleaning.ipynb
â”‚   â”œâ”€â”€ goods_parser.py
â”‚   â”œâ”€â”€ load_to_mysql.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql
â”‚   â”œâ”€â”€ analysis_queries.sql
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ trade_dashboard.pbix
â”‚
â””â”€â”€ README.md               # Project documentation

âœ”ï¸ Final Deliverables

Cleaned dataset (trade_cleaned.csv)

SQL database with analytical tables

Python scripts for the pipeline

Power BI dashboard with 4 analytical modules

Project documentation (this README)
